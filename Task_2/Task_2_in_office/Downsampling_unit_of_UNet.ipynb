{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание\n",
        "\n",
        "Реализация downsampling блока нейронной сети UNet.\n",
        "Вспомните общую архитектуру модели UNet. Первая ее часть, encoder,\n",
        "состоит из блоков (conv + relu -> conv + relu -> maxpoling). Они постепенно\n",
        "уменьшают размер feature maps и увеличивают количество слоев. Вам\n",
        "необходимо реализовать этот блок сети UNet. Проверьте вашу реализацию на\n",
        "примере случайного тензора, чтобы убедиться, что форма выходного тензора\n",
        "соответствует ожиданиям.\n",
        "\n",
        "Блок энкодера в модели UNet состоит из 2-х сверток 3*3 с функцией\n",
        "активации Relu после каждой из них, за которыми следует max_pooling с\n",
        "ядром 2*2, уменьшающий изображение в 2 раза, следовательно, нужно\n",
        "применить stride 2.\n",
        "Для проверки мы возьмем тензор размером 64*284*284. На выходе должны\n",
        "получить 128*140*140.\n",
        "\n",
        "Обращаем внимание, что при применении операции свертки размер\n",
        "изображения уменьшается на 2 пикселя. А значит тут мы не используем\n",
        "паддинг.\n"
      ],
      "metadata": {
        "id": "gmQWRQ2ZVCC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zIJzHoEuUoM-"
      },
      "outputs": [],
      "source": [
        "import torch  # Импорт библиотеки PyTorch — основного инструмента для создания и обучения нейронных сетей\n",
        "import torch.nn as nn  # Импорт подмодуля nn (нейронные сети), который содержит готовые слои и функции активации\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetBlock(nn.Module):  # Определяем блок U-Net, наследуем от nn.Module (базовый класс нейросетей в PyTorch)\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetBlock, self).__init__()  # Инициализация базового класса\n",
        "\n",
        "        # Первый сверточный слой:\n",
        "        # in_channels — число входных каналов (например, 3 для RGB),\n",
        "        # out_channels — число выходных каналов (фильтров),\n",
        "        # kernel_size=3 — размер фильтра 3x3,\n",
        "        # padding=0 — без добавления пикселей на границе, поэтому размер изображения после свертки уменьшится\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=0)\n",
        "\n",
        "        # Функция активации ReLU:\n",
        "        # inplace=True — изменяет данные на месте без создания нового объекта (экономит память)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Второй сверточный слой:\n",
        "        # in_channels и out_channels равны out_channels первого слоя,\n",
        "        # kernel_size и padding аналогичны первому,\n",
        "        # каждый сверточный слой — отдельный слой с собственными весами\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=0)\n",
        "\n",
        "        # Операция максимального объединения (max pooling):\n",
        "        # kernel_size=2 — берет максимум из каждой области 2x2,\n",
        "        # stride=2 — сдвигается на 2 пикселя, уменьшая размер изображения вдвое по ширине и высоте\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Прямой проход данных через блок\n",
        "\n",
        "        x = self.conv1(x)  # Проходим через первую свертку\n",
        "        x = self.relu(x)   # Применяем ReLU — обнуляем отрицательные значения\n",
        "        x = self.conv2(x)  # Проходим через вторую свертку\n",
        "        x = self.relu(x)   # Снова ReLU\n",
        "\n",
        "        pooled = self.pool(x)  # Применяем max pooling, уменьшая размер\n",
        "\n",
        "        # Возвращаем два значения:\n",
        "        # x — результат после двух сверток (будет использоваться для пропуска (skip connection) в U-Net),\n",
        "        # pooled — уменьшенная версия для следующего уровня сети\n",
        "        return x, pooled\n"
      ],
      "metadata": {
        "id": "_fAl_WIRWRrL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования блока UNetBlock с комментариями\n",
        "\n",
        "block = UNetBlock(64, 126)\n",
        "# Создаем объект блока, где:\n",
        "# 64 — число входных каналов (например, число признаков с предыдущего слоя)\n",
        "# 126 — число выходных каналов (число фильтров, которые блок должен обучить)\n",
        "\n",
        "input_tensor = torch.randn(1, 64, 284, 284)\n",
        "# Создаем входной тензор с случайными значениями:\n",
        "# 1 — размер батча (один пример),\n",
        "# 64 — число каналов (например, 64 признака),\n",
        "# 284x284 — высота и ширина изображения (пиксели)\n",
        "\n",
        "conv_output, pooled_output = block(input_tensor)\n",
        "# Передаем input_tensor в блок:\n",
        "# conv_output — результат после двух сверток (без уменьшения размерности пулингом),\n",
        "# pooled_output — результат после max pooling (с уменьшенной размерностью)\n",
        "\n",
        "print(conv_output.shape, pooled_output.shape)\n",
        "# Выводим размеры тензоров:\n",
        "# conv_output.shape — размер после двух сверток (будет меньше из-за отсутствия паддинга),\n",
        "# pooled_output.shape — размер после уменьшения max pooling'ом (в 2 раза меньше по ширине и высоте)\n",
        "\n",
        "# Почему размеры такие:\n",
        "# Каждая свертка с kernel_size=3 и padding=0 уменьшает размер на 2 пикселя с каждой стороны,\n",
        "# Значит 2 свертки уменьшат размер с 284 до 280 (284 - 2*2 = 280)\n",
        "# После этого max pooling с kernel_size=2 и stride=2 уменьшит 280 до 140 (половина)\n",
        "\n",
        "# Ожидаемые размеры:\n",
        "# conv_output.shape -> (1, 126, 280, 280)\n",
        "# pooled_output.shape -> (1, 126, 140, 140)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc0wrpnkWlVG",
        "outputId": "303fd07c-2a5d-4cc1-b530-e141de0516b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 126, 280, 280]) torch.Size([1, 126, 140, 140])\n"
          ]
        }
      ]
    }
  ]
}