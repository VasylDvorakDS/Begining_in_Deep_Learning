{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание\n",
        "\n",
        "Создание модели UNet.\n",
        "Используя ранее реализованные блоки, соберите полную модель UNet,\n",
        "соответствующую той, что была приведена на лекции.\n",
        "Определите encoder, bottleneck и decoder части сети, добавьте skip\n",
        "connections. Учтите, что для skipping connections тензоры необходимо\n",
        "обрезать до нужного размера.\n",
        "\n",
        "В сети UNet содержится:\n",
        "- 4 блока UNetBlock которые мы уже реализовали.\n",
        "- бутылочное горлышко. Заметим, что оно почти такое же, как UNetBlock, за\n",
        "исключением операции пулинга. Но это нам не помешает, так как наш\n",
        "UNetBlock возвращает и значения до этой операции\n",
        "- 4 блока апсемплинга UNetUpBlock, которые принимают как тензор, который\n",
        "мы будем увеличивать, так и skip connection тензор из энкодера.\n",
        "- Замыкающую операцию свертки с ядром 1 и двумя фильтрами.\n"
      ],
      "metadata": {
        "id": "D1WkL7uNsSKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hE6raurIsMZW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_tensor_to_match(tensor, target_tensor):\n",
        "    \"\"\"\n",
        "    Функция для обрезания тензора до размера, который должен быть в 2 раза больше размера target_tensor.\n",
        "    Аргументы:\n",
        "    - tensor: исходный тензор, который нужно обрезать.\n",
        "    - target_tensor: тензор, по размеру которого мы ориентируемся.\n",
        "\n",
        "    Задача: обрезать tensor так, чтобы его высота и ширина стали ровно в 2 раза больше, чем у target_tensor.\n",
        "\n",
        "    Пояснение по размерам тензоров:\n",
        "    - tensor.size() возвращает кортеж с размерами тензора в формате (batch_size, channels, height, width).\n",
        "    - target_tensor.size() — аналогично, размеры целевого тензора.\n",
        "\n",
        "    Переменные:\n",
        "    - target_x = target_tensor.size()[3] * 2\n",
        "      — ширина (axis 3) target_tensor, умноженная на 2.\n",
        "    - target_y = target_tensor.size()[2] * 2\n",
        "      — высота (axis 2) target_tensor, умноженная на 2.\n",
        "    - diffY = tensor.size()[2] - target_y\n",
        "      — разница между высотой исходного тензора и нужной высотой (в 2 раза больше целевого).\n",
        "    - diffX = tensor.size()[3] - target_x\n",
        "      — разница между шириной исходного тензора и нужной шириной.\n",
        "\n",
        "    Обрезание:\n",
        "    - Используем срезы по высоте и ширине:\n",
        "      tensor[:, :, start_y:end_y, start_x:end_x]\n",
        "      где start_y = diffY // 2 — сдвиг с верхнего края для центрирования обрезки,\n",
        "      end_y = start_y + target_y — конечная точка по высоте,\n",
        "      аналогично по ширине.\n",
        "\n",
        "    Возвращаемый результат:\n",
        "    - cropped_tensor — тензор, обрезанный по центру, с размерами (batch_size, channels, target_y, target_x),\n",
        "      то есть в 2 раза больше, чем размеры target_tensor.\n",
        "    \"\"\"\n",
        "    target_x = target_tensor.size()[3]*2  # вычисляем нужную ширину: в 2 раза больше, чем у target_tensor\n",
        "    target_y = target_tensor.size()[2]*2  # вычисляем нужную высоту: в 2 раза больше, чем у target_tensor\n",
        "    diffY = tensor.size()[2] - target_y   # на сколько исходный тензор больше по высоте\n",
        "    diffX = tensor.size()[3] - target_x   # на сколько исходный тензор больше по ширине\n",
        "    # обрезаем тензор по центру, сдвигаясь на половину излишка сверху и слева\n",
        "    cropped_tensor = tensor[:, :, diffY // 2: diffY // 2 + target_y, diffX // 2: diffX // 2 + target_x]\n",
        "    return cropped_tensor  # возвращаем обрезанный тензор\n"
      ],
      "metadata": {
        "id": "dpzYqQWatZJN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetBlock(nn.Module):  # Определяем блок U-Net, наследуем от nn.Module (базовый класс нейросетей в PyTorch)\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetBlock, self).__init__()  # Инициализация базового класса\n",
        "\n",
        "        # Первый сверточный слой:\n",
        "        # in_channels — число входных каналов (например, 3 для RGB),\n",
        "        # out_channels — число выходных каналов (фильтров),\n",
        "        # kernel_size=3 — размер фильтра 3x3,\n",
        "        # padding=0 — без добавления пикселей на границе, поэтому размер изображения после свертки уменьшится\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=0)\n",
        "\n",
        "        # Функция активации ReLU:\n",
        "        # inplace=True — изменяет данные на месте без создания нового объекта (экономит память)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Второй сверточный слой:\n",
        "        # in_channels и out_channels равны out_channels первого слоя,\n",
        "        # kernel_size и padding аналогичны первому,\n",
        "        # каждый сверточный слой — отдельный слой с собственными весами\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=0)\n",
        "\n",
        "        # Операция максимального объединения (max pooling):\n",
        "        # kernel_size=2 — берет максимум из каждой области 2x2,\n",
        "        # stride=2 — сдвигается на 2 пикселя, уменьшая размер изображения вдвое по ширине и высоте\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Прямой проход данных через блок\n",
        "\n",
        "        x = self.conv1(x)  # Проходим через первую свертку\n",
        "        x = self.relu(x)   # Применяем ReLU — обнуляем отрицательные значения\n",
        "        x = self.conv2(x)  # Проходим через вторую свертку\n",
        "        x = self.relu(x)   # Снова ReLU\n",
        "\n",
        "        pooled = self.pool(x)  # Применяем max pooling, уменьшая размер\n",
        "\n",
        "        # Возвращаем два значения:\n",
        "        # x — результат после двух сверток (будет использоваться для пропуска (skip connection) в U-Net),\n",
        "        # pooled — уменьшенная версия для следующего уровня сети\n",
        "        return x, pooled"
      ],
      "metadata": {
        "id": "q-VG3k6tvHAk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetUpBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetUpBlock, self).__init__()\n",
        "        # nn.ConvTranspose2d - транспонированная свертка, используется для увеличения пространственных размеров (upsampling).\n",
        "        # Параметры:\n",
        "        # in_channels - количество входных каналов,\n",
        "        # out_channels - количество выходных каналов,\n",
        "        # kernel_size=2 - размер ядра свертки 2x2,\n",
        "        # stride=2 - шаг 2 для удвоения размера входа (например, 64x64 -> 128x128).\n",
        "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "        # nn.Conv2d - обычная 2D-свертка для извлечения признаков.\n",
        "        # Параметры:\n",
        "        # in_channels - количество входных каналов,\n",
        "        # out_channels - количество выходных каналов,\n",
        "        # kernel_size=3 - размер ядра 3x3,\n",
        "        # padding=0 - без заполнения, поэтому размер выходного тензора уменьшается.\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=0)\n",
        "\n",
        "        # nn.ReLU - функция активации ReLU (Rectified Linear Unit),\n",
        "        # inplace=True означает, что операция делается \"на месте\" для экономии памяти.\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Второй сверточный слой с теми же параметрами, для более глубокого извлечения признаков.\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=0)\n",
        "\n",
        "    def forward(self, x, skip_connection):\n",
        "        # x - входной тензор (например, из предыдущего слоя U-Net, с уменьшенным пространственным размером).\n",
        "        # skip_connection - тензор из соответствующего слоя вниз по U-Net, для объединения деталей.\n",
        "\n",
        "        # Применяем транспонированную свертку для увеличения размера изображения (upsampling).\n",
        "        x = self.upconv(x)\n",
        "\n",
        "        # Объединяем (конкатенируем) по канальному измерению (dim=1)\n",
        "        # upsampled x и skip_connection, чтобы сохранить детали из ранних слоев.\n",
        "        x = torch.cat([x, skip_connection], dim=1)\n",
        "\n",
        "        # Пропускаем результат через первый сверточный слой для извлечения признаков.\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        # Применяем активацию ReLU для нелинейности.\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Пропускаем через второй сверточный слой для более детальной обработки.\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        # Снова ReLU активация.\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Возвращаем обработанный тензор.\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "_vl0-jQXvIOb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        # Инициализация блоков энкодера (сжатия)\n",
        "        # Каждый блок уменьшает размерность, увеличивает число каналов\n",
        "        self.enc1 = UNetBlock(1, 64)    # Вход 1 канал (например, grayscale), выход 64 канала\n",
        "        self.enc2 = UNetBlock(64, 128)  # Принимает 64 канала, отдаёт 128\n",
        "        self.enc3 = UNetBlock(128, 256) # Принимает 128, отдаёт 256\n",
        "        self.enc4 = UNetBlock(256, 512) # Принимает 256, отдаёт 512\n",
        "\n",
        "        # Бутылочное горлышко — самый глубокий слой с максимальным числом каналов\n",
        "        self.bottleneck = UNetBlock(512, 1024)  # 512 -> 1024 каналов\n",
        "\n",
        "        # Блоки декодера (расширения) — увеличивают размер изображения, уменьшают число каналов\n",
        "        self.up4 = UNetUpBlock(1024, 512)  # 1024 входных каналов, 512 выходных\n",
        "        self.up3 = UNetUpBlock(512, 256)   # 512 -> 256\n",
        "        self.up2 = UNetUpBlock(256, 128)   # 256 -> 128\n",
        "        self.up1 = UNetUpBlock(128, 64)    # 128 -> 64\n",
        "\n",
        "        # Финальный сверточный слой, kernel_size=1 — свертка 1x1 для уменьшения каналов до 2\n",
        "        # Обычно для сегментации с 2 классами (фон и объект)\n",
        "        self.final_conv = nn.Conv2d(64, 2, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Проход через энкодер:\n",
        "        # Каждый блок возвращает два значения: output (xN) и pooled output (pN)\n",
        "        x1, p1 = self.enc1.forward(x)  # Первый блок: вход x, выход x1, pooled p1\n",
        "        x2, p2 = self.enc2.forward(p1) # Второй блок: вход p1, выход x2, pooled p2\n",
        "        x3, p3 = self.enc3.forward(p2)\n",
        "        x4, p4 = self.enc4.forward(p3)\n",
        "\n",
        "        # Бутылочное горлышко:\n",
        "        # Нужен только первый выход (не pooled), тк это центр сети\n",
        "        x5, _ = self.bottleneck.forward(p4)\n",
        "\n",
        "        # Декодер:\n",
        "        # Здесь нужно соединить слои пропуска (skip connections) из энкодера с декодером\n",
        "        # Для этого обрезаем тензор x4 по размеру x5 (с помощью crop_tensor_to_match)\n",
        "        x4_skip = crop_tensor_to_match(x4, x5)\n",
        "        x = self.up4.forward(x5, x4_skip)  # Объединяем bottleneck и skip connection x4\n",
        "\n",
        "        x3_skip = crop_tensor_to_match(x3, x)  # Аналогично с x3\n",
        "        x = self.up3.forward(x, x3_skip)\n",
        "\n",
        "        x2_skip = crop_tensor_to_match(x2, x)\n",
        "        x = self.up2.forward(x, x2_skip)\n",
        "\n",
        "        x1_skip = crop_tensor_to_match(x1, x)\n",
        "        x = self.up1.forward(x, x1_skip)\n",
        "\n",
        "        # Финальный сверточный слой с ядром 1 для получения окончательного результата сегментации\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "FnmMq_t8ttwr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = UNet()\n",
        "# Создаем экземпляр модели UNet с заранее определённой архитектурой\n",
        "\n",
        "input_tensor = torch.randn(1, 1, 572, 572)\n",
        "# Создаем входной тензор:\n",
        "# 1 - batch size (один пример за раз)\n",
        "# 1 - количество каналов (например, grayscale изображение)\n",
        "# 572 x 572 - размер изображения (ширина и высота)\n",
        "# Значения случайные, с нормальным распределением (randn)\n",
        "\n",
        "output = model(input_tensor)\n",
        "# Прогоняем входной тензор через модель (прямой проход)\n",
        "# Результат — тензор выхода модели\n",
        "\n",
        "print(output.shape)\n",
        "# Печатаем размер выходного тензора\n",
        "# Ожидается, что размер будет примерно (1, 2, H_out, W_out)\n",
        "# где 2 — количество каналов на выходе (например, классы сегментации),\n",
        "# H_out и W_out зависят от архитектуры и паддингов свёрток.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq5iUMJ_uYd_",
        "outputId": "36be9b4c-5ef3-430c-dd6e-d7670161ccd6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 388, 388])\n"
          ]
        }
      ]
    }
  ]
}