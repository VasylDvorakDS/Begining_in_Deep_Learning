{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo --quiet"
      ],
      "metadata": {
        "id": "uFOC4sCSJpXO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gRFDIKryHHQ8"
      },
      "outputs": [],
      "source": [
        "import torch  # Импортируем библиотеку PyTorch — фреймворк для построения и обучения нейронных сетей.\n",
        "import torch.nn as nn  # Импортируем модуль для работы с готовыми слоями нейросети (например, свёртка, полносвязный слой).\n",
        "import torch.nn.functional as F  # Импортируем функциональный модуль — здесь доступны функции активации, свёртки и т.п.\n",
        "import torchinfo  # Импортируем torchinfo — библиотеку, которая позволяет красиво выводить информацию о модели (размеры входов, выходов, количество параметров и т.д.)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):  # Определяем класс нейросети, наследующий от базового класса nn.Module (все нейросети в PyTorch так строятся).\n",
        "    def __init__(self):  # Метод инициализации (конструктор). Здесь создаются и настраиваются слои нейросети.\n",
        "        super(SimpleCNN, self).__init__()  # Вызываем конструктор базового класса (nn.Module), чтобы всё работало корректно.\n",
        "\n",
        "        # Определяем первый свёрточный слой:\n",
        "        # nn.Conv2d — слой двумерной свёртки (обычно используется для обработки изображений).\n",
        "        # Аргументы:\n",
        "        # 1 — количество входных каналов (у черно-белого изображения 1 канал, у цветного — 3).\n",
        "        # 32 — количество выходных каналов (то есть фильтров; больше фильтров — больше признаков извлекается).\n",
        "        # kernel_size=3 — размер фильтра: 3x3 пикселя.\n",
        "        # padding=1 — добавим по 1 пикселю с каждой стороны изображения, чтобы размер после свёртки не уменьшился.\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "\n",
        "        # Определяем слой подвыборки (пулинга):\n",
        "        # MaxPool2d — слой максимального пулинга (берёт максимум из каждого маленького участка изображения).\n",
        "        # kernel_size=2 — берёт участки размером 2x2 пикселя.\n",
        "        # stride=2 — шаг смещения окна тоже 2, т.е. изображение уменьшается в 2 раза по ширине и высоте.\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Второй свёрточный слой:\n",
        "        # Входов уже 32 (из предыдущего conv1), выходов — 64 (в 2 раза больше признаков).\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        # Добавим два полносвязных слоя в класс SimpleCNN:\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        # nn.Linear — это полносвязный (fully connected, FC) слой.\n",
        "        # Аргументы:\n",
        "        # 64 * 7 * 7 — число входных признаков (features), приходящих из предыдущего слоя.\n",
        "        # Почему именно 64 * 7 * 7?\n",
        "        # - После двух свёрточных слоёв с паддингом=1 и двух MaxPool (kernel_size=2, stride=2),\n",
        "        #   исходное изображение 224x224 уменьшится в 2 раза → 112x112 после первого пулинга,\n",
        "        #   затем ещё в 2 раза → 56x56 после второго.\n",
        "        # - Однако в оригинальном коде был `.view(-1, 64 * 7 * 7)` — это значит, что вход должен быть 28x28, а не 224x224.\n",
        "        # - То есть реальный размер входного изображения должен быть 28x28, а не 224x224.\n",
        "        # - Тогда после двух пулингов: 28 → 14 → 7, и выходной тензор будет размером [batch_size, 64, 7, 7].\n",
        "        # - Его надо \"выровнять\" (flatten) в [batch_size, 64 * 7 * 7] = [batch_size, 3136].\n",
        "        # - Этот слой принимает 3136 признаков и выдаёт 128 новых признаков — скрытое представление.\n",
        "\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        # Второй полносвязный слой — выходной.\n",
        "        # Принимает 128 признаков со скрытого слоя и выдаёт 10 выходов.\n",
        "        # Почему 10?\n",
        "        # - Обычно это означает, что модель решает задачу классификации на 10 классов (например, цифры от 0 до 9 в MNIST).\n",
        "        # - Каждое значение — это \"оценка\" вероятности принадлежности к одному из 10 классов.\n",
        "        # - В конце используется F.log_softmax, чтобы превратить их в логарифмы вероятностей.\n",
        "\n",
        "\n",
        "    def forward(self, x):  # Метод прямого прохода (forward) — определяет, как данные проходят через слои.\n",
        "        # Пропускаем вход x через conv1, затем через ReLU (функция активации), затем через MaxPool:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Повторяем ту же операцию со вторым слоем:\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # После двух свёрток и двух пулингов изображение стало меньше, нужно преобразовать тензор в одномерный вектор:\n",
        "        # x.view(...) — меняет форму тензора.\n",
        "        # -1 — PyTorch сам подберёт размер батча, 64 * 7 * 7 — размерность признаков.\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "\n",
        "        # Далее — применение полносвязного слоя fc1, но он не определён — это вызовет ошибку.\n",
        "        x = F.relu(self.fc1(x))  # Активируем скрытый слой через ReLU.\n",
        "\n",
        "        # Выходной слой — применяем логарифм от softmax (логарифм вероятностей принадлежности к каждому классу):\n",
        "        x = F.log_softmax(self.fc2(x), dim=1)\n",
        "\n",
        "        return x  # Возвращаем результат — логарифмы вероятностей.\n",
        "\n",
        "# Пример использования:\n",
        "model = SimpleCNN()  # Создаём объект модели.\n",
        "\n",
        "# Используем torchinfo.summary — выводит таблицу с информацией о слоях, параметрах и размерах.\n",
        "# model — сама модель.\n",
        "# (1, 224, 224) — размер входного изображения: 1 канал, 224 пикселя высота, 224 ширина.\n",
        "# batch_dim=0 — первая размерность (по нулям) означает размер батча.\n",
        "# col_names — какие колонки выводить: размеры входов/выходов, число параметров, размер ядер, количество операций.\n",
        "# verbose=0 — отключаем подробный текст.\n",
        "torchinfo.summary(model, (1, 224, 224), batch_dim=0,\n",
        "    col_names=('input_size', 'output_size', 'num_params', 'kernel_size', 'mult_adds'),\n",
        "    verbose=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXkwe8AyJK6i",
        "outputId": "9eaf2427-2f4d-45a9-9d93-c61d3d1179e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=====================================================================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
              "=====================================================================================================================================================================\n",
              "SimpleCNN                                [1, 1, 224, 224]          [64, 10]                  --                        --                        --\n",
              "├─Conv2d: 1-1                            [1, 1, 224, 224]          [1, 32, 224, 224]         320                       [3, 3]                    16,056,320\n",
              "├─MaxPool2d: 1-2                         [1, 32, 224, 224]         [1, 32, 112, 112]         --                        2                         --\n",
              "├─Conv2d: 1-3                            [1, 32, 112, 112]         [1, 64, 112, 112]         18,496                    [3, 3]                    232,013,824\n",
              "├─MaxPool2d: 1-4                         [1, 64, 112, 112]         [1, 64, 56, 56]           --                        2                         --\n",
              "├─Linear: 1-5                            [1, 3136]                 [64, 128]                 401,536                   --                        25,698,304\n",
              "├─Linear: 1-6                            [1, 128]                  [64, 10]                  1,290                     --                        82,560\n",
              "=====================================================================================================================================================================\n",
              "Total params: 421,642\n",
              "Trainable params: 421,642\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 273.85\n",
              "=====================================================================================================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 19.34\n",
              "Params size (MB): 1.69\n",
              "Estimated Total Size (MB): 21.23\n",
              "====================================================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchinfo.summary вывёл подробную таблицу по слоям нейросети. Вот объяснение каждой строки и столбца:\n",
        "\n",
        "# Модель: SimpleCNN — имя нашей модели.\n",
        "\n",
        "# Вход: [1, 1, 224, 224]\n",
        "# - Batch size: 1 (одна картинка за раз)\n",
        "# - Каналов: 1 (чёрно-белое изображение)\n",
        "# - Высота и ширина: 224x224 пикселя\n",
        "\n",
        "# ├─Conv2d: 1-1 — первый сверточный слой\n",
        "#   Input Shape: [1, 1, 224, 224] — один канал, 224x224 пикселя\n",
        "#   Output Shape: [1, 32, 224, 224] — 32 канала (фильтра), тот же размер (padding=1)\n",
        "#   Param #: 320 — (1 вход * 3 * 3 + 1 смещение) * 32 фильтра = 320\n",
        "#   Kernel Shape: [3, 3] — ядро 3x3\n",
        "#   Mult-Adds: 16,056,320 — операций умножений и сложений: сколько операций нужно сделать для одного прохода по данным\n",
        "\n",
        "# ├─MaxPool2d: 1-2 — первый пулинг (подвыборка)\n",
        "#   Output Shape: [1, 32, 112, 112] — размер уменьшен в 2 раза по ширине и высоте\n",
        "\n",
        "# ├─Conv2d: 1-3 — второй сверточный слой\n",
        "#   Input Shape: [1, 32, 112, 112]\n",
        "#   Output Shape: [1, 64, 112, 112] — стало 64 каналов\n",
        "#   Param #: 18,496 — (32 входных каналов * 3 * 3 + 1 смещение) * 64 фильтра = 18,496 параметров\n",
        "#   Mult-Adds: 232,013,824 — огромный объём операций на втором свёрточном слое\n",
        "\n",
        "# ├─MaxPool2d: 1-4 — второй пулинг\n",
        "#   Output Shape: [1, 64, 56, 56] — снова уменьшаем размер в 2 раза\n",
        "\n",
        "# ├─Linear: 1-5 — первый полносвязный слой (fc1)\n",
        "#   Input Shape: [1, 3136] — 64 * 56 * 56 = 200704, но model.view(-1, 64*7*7) рассчитан на [1, 3136]\n",
        "#   В коде ошибка: текущая выходная форма — 64 * 56 * 56 = 200704, а ожидается 3136 → несовпадение\n",
        "#   Output Shape: [64, 128] — батч 64 элементов, каждый со 128 признаками\n",
        "#   Param #: 401,536 — (3136 входов + 1 смещение) * 128 выходов\n",
        "#   Mult-Adds: 25,698,304 — вычислительные операции на этом слое\n",
        "\n",
        "# ├─Linear: 1-6 — второй полносвязный слой (fc2)\n",
        "#   Input Shape: [1, 128]\n",
        "#   Output Shape: [64, 10] — 10 выходных классов\n",
        "#   Param #: 1,290 — (128 входов + 1 смещение) * 10 выходов\n",
        "#   Mult-Adds: 82,560 — сравнительно немного операций\n",
        "\n",
        "# ИТОГ:\n",
        "# Total params: 421,642 — общее количество обучаемых параметров (веса и смещения)\n",
        "# Все параметры — trainable (могут изменяться при обучении)\n",
        "\n",
        "# Mult-adds (умножения и сложения): 273.85 МЕГАопераций — это показатель вычислительной нагрузки.\n",
        "\n",
        "# Estimated Total Size (MB): 21.23\n",
        "# Input: 0.20 MB — размер входного изображения\n",
        "# Forward/backward pass: 19.34 MB — память, занимаемая при прохождении данных\n",
        "# Params size: 1.69 MB — вес всех параметров модели\n",
        "# Total: ~21 MB — сколько потребуется оперативной памяти на один проход\n"
      ],
      "metadata": {
        "id": "PMH3K4_MLpkG"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}