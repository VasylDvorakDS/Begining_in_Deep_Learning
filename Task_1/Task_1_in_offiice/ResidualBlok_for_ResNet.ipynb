{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание\n",
        "\n",
        "Реализуйте ResidualBlok, применяемый в ResNet. В решении\n",
        "используйте свертки с ядром 3, padding = 1 и stride = 1. Число каналов в\n",
        "тензоре не должно поменяться.\n"
      ],
      "metadata": {
        "id": "VZY5yTIlfY1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch          # Основная библиотека PyTorch для работы с тензорами и вычислениями\n",
        "import torch.nn as nn # Модуль с определениями нейронных сетевых слоев и архитектур\n",
        "import torch.nn.functional as F  # Модуль с функциональными API, например активациями, потерями, и пр."
      ],
      "metadata": {
        "id": "j7D-pua6eZcP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mec-jhrUdEUf",
        "outputId": "5ff17a11-fa00-4d01-bff6-ebbcc8c27e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        # Первый сверточный слой (Conv2d):\n",
        "        # - channels: число входных и выходных каналов (т.к. слои сохраняют размерность)\n",
        "        # - kernel_size=3: размер ядра свертки 3x3, что хорошо для захвата локальных признаков\n",
        "        # - stride=1: шаг свертки равен 1, значит размер выхода не уменьшается\n",
        "        # - padding=1: добавляем 1 пиксель по краям, чтобы сохранить размер входа и выхода одинаковым\n",
        "        # - bias=False: смещение (биас) не используется, т.к. есть нормализация или для упрощения модели\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "\n",
        "        # Второй сверточный слой с теми же параметрами, чтобы глубже обработать признаки\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Функция forward описывает, как данные проходят через блок при прямом проходе\n",
        "        # x — входной тензор с формой [batch_size, channels, height, width]\n",
        "\n",
        "        # Пропускаем вход x через первый сверточный слой, затем применяем ReLU активацию,\n",
        "        # которая добавляет нелинейность и \"обнуляет\" отрицательные значения\n",
        "        out = F.relu(self.conv1(x))\n",
        "\n",
        "        # Далее пропускаем полученный результат через второй сверточный слой без активации,\n",
        "        # чтобы получить новые признаки\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        # Добавляем исходный вход x к выходу второго слоя — это называется \"пропускной путь\" или skip connection,\n",
        "        # который помогает избежать проблемы исчезающего градиента и облегчает обучение глубоких сетей\n",
        "        out += x\n",
        "        # Применяем ReLU активацию к сумме, чтобы сохранить нелинейность после добавления\n",
        "        out = F.relu(out)\n",
        "\n",
        "        # Возвращаем итоговый тензор с теми же размерами, что и вход\n",
        "        return out\n",
        "\n",
        "# Пример использования ResidualBlock:\n",
        "res_block = ResidualBlock(64)\n",
        "# Создаем случайный входной тензор:\n",
        "# torch.randn — генерирует тензор с нормальным распределением\n",
        "# Размерность: 1 — размер батча (кол-во изображений в пакете)\n",
        "# 64 — количество каналов (например, признаков)\n",
        "# 32x32 — высота и ширина изображения\n",
        "input_tensor = torch.randn(1, 64, 32, 32)\n",
        "\n",
        "# Передаем входной тензор через residual блок\n",
        "output_tensor = res_block(input_tensor)\n",
        "\n",
        "# Печатаем размерность выходного тензора:\n",
        "# Ожидаем ту же форму, что и у входа: (1, 64, 32, 32)\n",
        "print(output_tensor.shape)\n",
        "\n"
      ]
    }
  ]
}