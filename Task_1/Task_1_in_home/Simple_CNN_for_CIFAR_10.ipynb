{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание:\n",
        "\n",
        "Обучить нейросеть на датасете  CIFAR 10. Это датасет из 60000 изображений разделенных на 10 классов. А также оцените качество работы этой модели.\n"
      ],
      "metadata": {
        "id": "fPgyv1bq3pBh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ziNn3Oj_3e4l"
      },
      "outputs": [],
      "source": [
        "import torch  # Основная библиотека PyTorch для работы с тензорами и вычислениями на GPU/CPU\n",
        "import torch.nn as nn  # Модуль для построения нейронных сетей (слои, активации и т.п.)\n",
        "import torch.optim as optim  # Модуль для оптимизаторов — алгоритмов обновления весов сети\n",
        "import torchvision  # Библиотека с готовыми датасетами, моделями и преобразованиями для компьютерного зрения\n",
        "import torchvision.transforms as transforms  # Модуль для преобразований изображений (аугментации, нормализация)\n",
        "import matplotlib.pyplot as plt  # Библиотека для визуализации графиков и изображений"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # nn.Conv2d: сверточный слой с параметрами:\n",
        "        # 3 входных канала (RGB), 32 выходных фильтра, ядро 3x3, паддинг 1 (чтобы сохранить размер)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        # nn.MaxPool2d: операция подвыборки с ядром 2x2 и шагом 2, уменьшает размер в 2 раза\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Второй сверточный слой: 32 входных канала, 64 выходных фильтра, ядро 3x3, паддинг 1\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        # Полносвязный слой (fc1): входной размер - 64 канала * 8 * 8 (размер после 2 пуллингов),\n",
        "        # выход 128 нейронов\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        # Полносвязный слой (fc2): вход 128 нейронов, выход 10 классов (CIFAR-10)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # F.relu — функция активации ReLU, добавляет нелинейность\n",
        "        # Сначала свертка conv1 + ReLU + пуллинг (уменьшение размера вдвое)\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        # Далее свертка conv2 + ReLU + пуллинг (еще раз уменьшаем размер)\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        # x.view преобразует тензор в плоский вид (-1 — размер батча, 64*8*8 — размер признаков)\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        # Полносвязный слой с ReLU\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        # Финальный слой с логарифмом вероятностей по классам (log_softmax)\n",
        "        x = torch.log_softmax(self.fc2(x), dim=1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HCMAlv7K4V14"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка и предобработка датасета CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # преобразует PIL-изображение в тензор (значения [0,1])\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    # нормализация каждого канала (R,G,B): вычитаем среднее 0.5 и делим на std 0.5\n",
        "    # для ускорения и стабилизации обучения\n",
        "])\n",
        "\n",
        "# train=True — загружаем тренировочную часть датасета, download=True — скачиваем, если нет локально\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "# DataLoader — удобный класс для загрузки данных пакетами (batch_size=100), shuffle=True перемешивает данные\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "# Аналогично для тестового набора\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Классы CIFAR-10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW_HQEK342ZR",
        "outputId": "0c6bf2be-50ee-45b5-af81-c3c0c296c40b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:12<00:00, 13.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Инициализация сети, функции потерь и оптимизатора\n",
        "net = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# CrossEntropyLoss — стандартная функция потерь для задач классификации, учитывает softmax\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "# SGD — стохастический градиентный спуск с learning rate=0.001 и моментумом 0.9 (ускоряет обучение)\n",
        "\n",
        "# Обучение сети\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):  # цикл по эпохам (полный проход по датасету)\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data  # получаем входные изображения и метки классов\n",
        "        optimizer.zero_grad()  # обнуляем градиенты перед обратным проходом\n",
        "\n",
        "        outputs = net(inputs)  # прямой проход: считаем предсказания сети\n",
        "        loss = criterion(outputs, labels)  # вычисляем ошибку (потерю)\n",
        "        loss.backward()  # обратное распространение ошибки — вычисляем градиенты\n",
        "        optimizer.step()  # обновляем веса модели на основе градиентов\n",
        "\n",
        "        running_loss += loss.item()  # накапливаем потерю для вывода\n",
        "        if i % 100 == 99:  # каждые 100 пакетов выводим среднюю потерю\n",
        "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Тестирование модели на тестовом наборе\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # отключаем вычисление градиентов, чтобы сэкономить память и время\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        outputs = net(inputs)  # предсказания модели\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # torch.max выбирает класс с максимальной вероятностью по dim=1 (по классам)\n",
        "        total += labels.size(0)  # суммируем общее количество примеров\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        # считаем количество правильных предсказаний\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
        "# Выводим точность — процент правильных предсказаний на тесте\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08W258-55AHY",
        "outputId": "e049bdc3-bdf3-473d-eb5e-d4902d874b6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 2.294\n",
            "[Epoch 1, Batch 200] loss: 2.261\n",
            "[Epoch 1, Batch 300] loss: 2.190\n",
            "[Epoch 1, Batch 400] loss: 2.071\n",
            "[Epoch 1, Batch 500] loss: 1.992\n",
            "[Epoch 2, Batch 100] loss: 1.909\n",
            "[Epoch 2, Batch 200] loss: 1.854\n",
            "[Epoch 2, Batch 300] loss: 1.803\n",
            "[Epoch 2, Batch 400] loss: 1.768\n",
            "[Epoch 2, Batch 500] loss: 1.734\n",
            "[Epoch 3, Batch 100] loss: 1.710\n",
            "[Epoch 3, Batch 200] loss: 1.667\n",
            "[Epoch 3, Batch 300] loss: 1.627\n",
            "[Epoch 3, Batch 400] loss: 1.605\n",
            "[Epoch 3, Batch 500] loss: 1.582\n",
            "[Epoch 4, Batch 100] loss: 1.544\n",
            "[Epoch 4, Batch 200] loss: 1.525\n",
            "[Epoch 4, Batch 300] loss: 1.507\n",
            "[Epoch 4, Batch 400] loss: 1.469\n",
            "[Epoch 4, Batch 500] loss: 1.459\n",
            "[Epoch 5, Batch 100] loss: 1.421\n",
            "[Epoch 5, Batch 200] loss: 1.412\n",
            "[Epoch 5, Batch 300] loss: 1.401\n",
            "[Epoch 5, Batch 400] loss: 1.401\n",
            "[Epoch 5, Batch 500] loss: 1.376\n",
            "[Epoch 6, Batch 100] loss: 1.355\n",
            "[Epoch 6, Batch 200] loss: 1.339\n",
            "[Epoch 6, Batch 300] loss: 1.342\n",
            "[Epoch 6, Batch 400] loss: 1.325\n",
            "[Epoch 6, Batch 500] loss: 1.310\n",
            "[Epoch 7, Batch 100] loss: 1.284\n",
            "[Epoch 7, Batch 200] loss: 1.271\n",
            "[Epoch 7, Batch 300] loss: 1.290\n",
            "[Epoch 7, Batch 400] loss: 1.278\n",
            "[Epoch 7, Batch 500] loss: 1.278\n",
            "[Epoch 8, Batch 100] loss: 1.247\n",
            "[Epoch 8, Batch 200] loss: 1.233\n",
            "[Epoch 8, Batch 300] loss: 1.238\n",
            "[Epoch 8, Batch 400] loss: 1.222\n",
            "[Epoch 8, Batch 500] loss: 1.233\n",
            "[Epoch 9, Batch 100] loss: 1.190\n",
            "[Epoch 9, Batch 200] loss: 1.207\n",
            "[Epoch 9, Batch 300] loss: 1.192\n",
            "[Epoch 9, Batch 400] loss: 1.189\n",
            "[Epoch 9, Batch 500] loss: 1.189\n",
            "[Epoch 10, Batch 100] loss: 1.152\n",
            "[Epoch 10, Batch 200] loss: 1.179\n",
            "[Epoch 10, Batch 300] loss: 1.158\n",
            "[Epoch 10, Batch 400] loss: 1.135\n",
            "[Epoch 10, Batch 500] loss: 1.149\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 58.16 %\n"
          ]
        }
      ]
    }
  ]
}